# Slimmable UNet: semantic segmentation with PyTorch for different calculation environments
## Usage
**Note : Use Python 3.6 or newer**
### Prediction

After training your model and saving it to MODEL.pth, you can easily test the output masks on your images via the CLI.

To predict a single image and save it:

`python predict.py -i image.jpg -o output.jpg`

To predict a multiple images and show them without saving them:

`python predict.py -i image1.jpg image2.jpg --viz --no-save`

### Training

```shell script
for CVC_Clinic DB dataset
> python train_cvc.py -h
usage: train.py [-h] [-e E] [-b [B]] [-l [LR]] [-f LOAD] [-s SCALE] [-v VAL]

Train the UNet on images and target masks

optional arguments:
  -h, --help            show this help message and exit
  -e E, --epochs E      Number of epochs (default: 5)
  -b [B], --batch-size [B]
                        Batch size (default: 1)
  -l [LR], --learning-rate [LR]
                        Learning rate (default: 0.1)
  -f LOAD, --load LOAD  Load model from a .pth file (default: False)
  -s SCALE, --scale SCALE
                        Downscaling factor of the images (default: 0.5)
  -v VAL, --validation VAL
                        Percent of the data that is used as validation (0-100)
                        (default: 15.0)
  -d                    Training model depth (if you use structured dropout or sandwich rule, set this "all".default: "all")
  -dr                   Whether we use structured dropout (default: "False")

```
By default, the `scale` is 0.5, so if you wish to obtain better results (but use more memory), set it to 1.
